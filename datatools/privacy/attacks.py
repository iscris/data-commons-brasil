import privattacks as pa
from pathlib import Path
from datetime import datetime
import json
import os
import sys
import argparse
import textwrap

def read_data(dataset_path:str, qids:list[str], sensitive:list[str], encoding="latin1"):
    """Read a dataset and return only the columns corresponding to quasi-identifiers and sensitive attributes.
    
    Parameters:
        dataset_path (list[str]): Dataset path.
        qids (list[str]): List of quasi-identifiers.
        sensitive (list[str]): List of sensitive attributes.
        encoding (str): Encoding.

    Return:
        data (privattacks.Data): Privattacks Data object containing the datset.
    """
    return pa.Data(dataset_path, cols=qids+sensitive, encoding=encoding)

def run_attacks(data:pa.Data, qids:list[str], sensitive:list[str], n_processes=1):
    """Run re-identification and attribute inference attacks.

    Parameters:
        data (privattacks.Data): Privattacks Data object.
        qids (list[str]): List of quasi-identifiers.
        sensitive (list[str]): List of sensitive attributes.
        n_processses (int): Number of cores to run in parallel.

    Return:
        priors (dict): Dictionary with values 'reid' and 'ai' and their respective prior vulnerabilities.
        posteriors (dict): Dictionary with values 'reid' and 'ai' and their respective posterior vulnerabilities.
    """
    attack = pa.Attack(data)
    priors = attack.prior_vulnerability(atk="all", sensitive=sensitive)
    posteriors = attack.posterior_vulnerability(
        atk="all",
        qids=qids,
        sensitive=sensitive,
        combinations=list(range(1, len(qids)+1)), # Power set
        n_processes=n_processes
    )
    return priors, posteriors

def save_results(priors, posteriors, sensitive:list[str], save_file:str):
    """Save results generated by method 'run_attacks'.
    
    Parameters:
        priors (dict): Dictionary with values 'reid' and 'ai' and their respective prior vulnerabilities.
        posteriors (pandas.DataFrame): Pandas DataFrame with re-identification and attribute inference attack results.
        sensitive (list[str]): List of sensitive attributes.
        save_file (str): Path to save the results. The results will be in csv format.
    """
    
    # It's assumed
    # Add prior of re-identification attacks
    posteriors["prior_reid"] = priors["reid"]
    
    # Add prior of attribute inference attacks
    for sens in sensitive:
        posteriors[f"prior_ai_{sens}"] = priors["ai"][sens]

    # Save results
    posteriors.to_csv(save_file, index=False)

def main():
    # Log function
    log = lambda msg : print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

    # Create the parser
    parser = argparse.ArgumentParser(
        description=textwrap.dedent("""Re-identification and attribute inference analysis.\n"""+
        """The script's output are going to be saved in the 'results' folder containing one CSV file per datset provided in --datasets parameter."""), formatter_class=argparse.RawTextHelpFormatter
    )

    # Add arguments
    parser.add_argument(
        "--datasets",
        type=str,
        required=True,
        help=textwrap.dedent("""\
                            JSON file (relative path) with information about the datasets to be analized.
                            It must containg a list of dictionaries where each dictionary contains the following fields about a dataset:
                                - Name: Dataset's name.
                                - Link: Link to the dataset's source.
                                - Sensitive information: String describing the sensitive information contained in the dataset.
                                - QIDs: List of quasi-identifiers (column names).
                                - Sensitive attributes: List of sensitive attributes (column names).
                                - Path: Relative path of the dataset's CSV file.""")
    )
    parser.add_argument("--processes", type=int, default=1, help="Number of processes to run in parallel.")

    # Parse arguments
    args = parser.parse_args()
    
    # JSON file containing the following fields: Name, Link, Sensitive Information, QIDs, Sensitive attributes, Path.
    datasets_info_path = Path().cwd() / args.datasets
    with open(datasets_info_path, "r", encoding="utf-8") as f:
        datasets_info = json.load(f)

    # Number of processes
    n_processes = args.processes

    # Create results folder
    results_path = Path().cwd() / "results"
    if not results_path.exists():
        os.mkdir(results_path.absolute())

    log(f"Starting privacy analysis")
    log(f"Command line: {' '.join(sys.argv)}")
    log(f"Running with {n_processes} {'process' if n_processes == 1 else 'processes'}")

    # Run attacks
    for dataset in datasets_info:
        dataset_path = Path().cwd() / Path(dataset["Path"]) # Relative path to this script
        dataset_results = results_path / f"{dataset_path.stem}_results.csv"

        # Skip the dataset if the results file already exists
        if dataset_results.exists():
            log(f"Skipping analysis for \"{dataset['Name']}\", the result file {dataset_results} alerady exists.")
            continue

        log(f"Analyzing dataset \"{dataset['Name']}\"")
        qids = dataset["QIDs"]
        sensitive = dataset["Sensitive attributes"]

        log(f"Reading data...")
        data = read_data(dataset_path.absolute(), qids, sensitive)

        log(f"Running attacks...")
        priors, posteriors = run_attacks(data, qids, sensitive)

        log(f"Saving results...")
        save_results(priors, posteriors, sensitive, dataset_results)
        log(f"Results saved at \"{dataset_results}\".")

if __name__ == "__main__":
    main()