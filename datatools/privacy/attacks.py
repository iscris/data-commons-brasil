import privattacks as pa
from pathlib import Path
from datetime import datetime
import json
import os

def read_data(dataset_path:str, qids:list[str], sensitive:list[str], encoding="latin1"):
    """Read a dataset and return only the columns corresponding to quasi-identifiers and sensitive attributes.
    
    Parameters:
        dataset_path (list[str]): Dataset path.
        qids (list[str]): List of quasi-identifiers.
        sensitive (list[str]): List of sensitive attributes.
        encoding (str): Encoding.

    Return:
        data (privattacks.Data): Privattacks Data object containing the datset.
    """
    return pa.Data(dataset_path, cols=qids+sensitive, encoding=encoding)

def run_attacks(data:pa.Data, qids:list[str], sensitive:list[str], n_processes=1):
    """Run re-identification and attribute inference attacks.

    Parameters:
        data (privattacks.Data): Privattacks Data object.
        qids (list[str]): List of quasi-identifiers.
        sensitive (list[str]): List of sensitive attributes.
        n_processses (int): Number of cores to run in parallel.

    Return:
        priors (dict): Dictionary with values 'reid' and 'ai' and their respective prior vulnerabilities.
        posteriors (dict): Dictionary with values 'reid' and 'ai' and their respective posterior vulnerabilities.
    """
    attack = pa.Attack(data)
    priors = attack.prior_vulnerability(atk="all", sensitive=sensitive)
    posteriors = attack.posterior_vulnerability(
        atk="all",
        qids=qids,
        sensitive=sensitive,
        combinations=list(range(1, len(qids)+1)), # Power set
        n_processes=n_processes
    )
    return priors, posteriors

def save_results(priors, posteriors, sensitive:list[str], save_file:str):
    """Save results generated by method 'run_attacks'.
    
    Parameters:
        priors (dict): Dictionary with values 'reid' and 'ai' and their respective prior vulnerabilities.
        posteriors (pandas.DataFrame): Pandas DataFrame with re-identification and attribute inference attack results.
        sensitive (list[str]): List of sensitive attributes.
        save_file (str): Path to save the results. The results will be in csv format.
    """
    
    # It's assumed
    # Add prior of re-identification attacks
    posteriors["prior_reid"] = priors["reid"]
    
    # Add prior of attribute inference attacks
    for sens in sensitive:
        posteriors[f"prior_ai_{sens}"] = priors["ai"][sens]

    # Save results
    posteriors.to_csv(save_file, index=False)

def main():
    # Log function
    log = lambda msg : print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

    # Create results folder
    results_path = Path().cwd() / "results"
    if not results_path.exists():
        os.mkdir(results_path.absolute())

    # JSON file containing the following fields: Name, Link, Sensitive Information, QIDs, Sensitive attributes, Path.
    datasets_info_path = Path().cwd() / "datasus_datasets_info.json"
    with open(datasets_info_path, "r", encoding="utf-8") as f:
        datasets_info = json.load(f)

    for dataset in datasets_info:
        log(f"Starting privacy analysis of dataset {dataset['Name']}")
        qids = dataset["QIDs"]
        sensitive = dataset["Sensitive attributes"]
        dataset_path = Path(dataset["Path"])

        log(f"Reading data")
        data = read_data(dataset_path.absolute(), qids, sensitive)
        log(f"Finished reading")

        log(f"Running attacks")
        priors, posteriors = run_attacks(data, qids, sensitive)
        log(f"Finished attacks")

        log(f"Saving results")
        dataset_results = results_path / f"{dataset_path.stem}_results.csv"
        save_results(priors, posteriors, sensitive, dataset_results)
        log(f"Results saved at '{dataset_results}'")

if __name__ == "__main__":
    main()